{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJOBqjOc5mZQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIB4Yru35mZS"
   },
   "outputs": [],
   "source": [
    "LANG_SRC = \"python\"\n",
    "LANG_DST = \"java\"\n",
    "\n",
    "MODEL_TYPE = \"roberta\"\n",
    "PRETRAINED_MODEL = \"microsoft/unixcoder-base\"\n",
    "\n",
    "N_EPOCHS = 15\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "BEAM_SIZE = 10\n",
    "MAX_SOURCE_LEN = 256\n",
    "MAX_TARGET_LEN = 128\n",
    "\n",
    "BATCH_SIZE_EVAL = 256\n",
    "BATCH_SIZE_TRAIN = 256\n",
    "\n",
    "MINI_DATASET_SIZE = 4096\n",
    "MINI_MODE_ENABLED = False\n",
    "\n",
    "FILENAME_JSONL_TEST = \"test.jsonl\"\n",
    "FILENAME_JSONL_TRAIN = \"train.jsonl\"\n",
    "FILENAME_JSONL_VALID = \"valid.jsonl\"\n",
    "\n",
    "FILENAME_JSONL_TEST_MINI = \"test-mini.jsonl\"\n",
    "FILENAME_JSONL_TRAIN_MINI = \"train-mini.jsonl\"\n",
    "FILENAME_JSONL_VALID_MINI = \"valid-mini.jsonl\"\n",
    "\n",
    "FILENAME_CSV_BLEU_SCORES = \"bleu_scores.csv\"\n",
    "FILENAME_CSV_EVAL_LOSSES = \"eval_losses.csv\"\n",
    "FILENAME_CSV_TRAIN_LOSSES = \"train_losses.csv\"\n",
    "FILENAME_TXT_BLEU_SCORE_TEST = \"bleu_score.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJb4pLJn5mZT"
   },
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(os.curdir)\n",
    "root_path = os.path.dirname(notebook_path)\n",
    "\n",
    "repo_path = os.path.join(root_path, \"repos\", \"CodeXGLUE\")\n",
    "task_path = os.path.join(repo_path, \"Code-Text\", \"code-to-text\")\n",
    "\n",
    "src_root_path = os.path.join(root_path, \"src\", \"python\")\n",
    "src_task_path = os.path.join(src_root_path, \"codexglue\", \"summarization\")\n",
    "\n",
    "code_path = os.path.join(task_path, \"code\")\n",
    "dataset_path = os.path.join(task_path, \"dataset\")\n",
    "evaluator_path = os.path.join(task_path, \"evaluator\")\n",
    "\n",
    "model_path = os.path.join(notebook_path, \"model\")\n",
    "src_notebook_path = os.path.join(notebook_path, \"src\")\n",
    "\n",
    "model_name = \"{dataset}-{task}-{model_type}-{pretrained_model}-{lang}-n_epochs={n_epochs}-lr={lr}\" \\\n",
    "    .format(\n",
    "        lang=LANG_SRC\n",
    "        , lr=LEARNING_RATE\n",
    "        , n_epochs=N_EPOCHS\n",
    "        , dataset=\"codexglue\"\n",
    "        , task=\"summarization\"\n",
    "        , model_type=MODEL_TYPE\n",
    "        , pretrained_model=PRETRAINED_MODEL.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGhieuEoGf13"
   },
   "outputs": [],
   "source": [
    "subprocess.check_call(\n",
    "    [\n",
    "        \"python\"\n",
    "        \n",
    "        , os.path.join(code_path, \"run.py\")\n",
    "        \n",
    "        , \"--model_type\", MODEL_TYPE\n",
    "        , \"--model_name_or_path\", PRETRAINED_MODEL\n",
    "        , \"--output_dir\", model_path\n",
    "        , \"--load_model_path\", os.path.join(model_path, \"checkpoint-best-bleu\", \"pytorch_model.bin\")\n",
    "\n",
    "        , \"--beam_size\", str(BEAM_SIZE)\n",
    "        , \"--max_source_length\", str(MAX_SOURCE_LEN)\n",
    "        , \"--max_target_length\", str(MAX_TARGET_LEN)\n",
    "\n",
    "        , \"--do_test\"\n",
    "        , \"--eval_batch_size\", str(BATCH_SIZE_EVAL)\n",
    "        , \"--test_filename\", os.path.join(\n",
    "            dataset_path\n",
    "            , LANG_DST\n",
    "            , FILENAME_JSONL_TEST if not MINI_MODE_ENABLED else FILENAME_JSONL_TEST_MINI\n",
    "        )\n",
    "\n",
    "        , \"--bleu_score_test_txt_filename\", os.path.join(model_path, FILENAME_TXT_BLEU_SCORE_TEST)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, FILENAME_TXT_BLEU_SCORE_TEST), 'r') as bleu_score_test_file:\n",
    "    print(\"Test Bleu score: \", bleu_score_test_file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 test data ground truth summaries of code in {lang_dst} language:\\n\".format(lang_dst=LANG_DST))\n",
    "\n",
    "with open(os.path.join(model_path, \"test_0.gold\"), mode=\"r\") as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 test data predicted summaries of code in {lang_dst} language using the trained {model_name} model:\\n\".format(lang_dst=LANG_DST, model_name=model_name))\n",
    "\n",
    "with open(os.path.join(model_path, \"test_0.output\"), mode=\"r\") as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "dataset=codexglue-task=summarization-model_type=roberta-pretrained_model=codebert-lang=python.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "1bd664d798eaef90b759c461f8ddc88e16fa212736979b86e27c0afa80cea1c1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
